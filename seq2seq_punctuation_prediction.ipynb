{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "seq2seq_punctuation_prediction_(1) (1).ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XDniUtS-ZSUA",
        "colab_type": "text"
      },
      "source": [
        "This notebook to train sequence to sequence model for Arabic punctuation prediction. This project followed the [Neural Machine Translation]((https://www.tensorflow.org/tutorials/text/nmt_with_attention)) which available from TensorFlow.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k3tpNu5xWvCp",
        "colab_type": "text"
      },
      "source": [
        "### Import necessary libraries\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "GpdedrlzyueD",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 79
        },
        "outputId": "d0844542-a8d0-4ed1-aba4-8948b8f1d92e"
      },
      "source": [
        "from __future__ import absolute_import, division, print_function, unicode_literals\n",
        "\n",
        "import tensorflow as tf\n",
        "tf.enable_eager_execution()\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.ticker as ticker\n",
        "from sklearn.utils import shuffle\n",
        "\n",
        "import numpy as np\n",
        "import os\n",
        "import time\n",
        "import pandas as pd\n",
        "import keras\n",
        "from nltk.translate.bleu_score import corpus_bleu\n",
        "from time import sleep\n",
        "import sys\n",
        "\n",
        "from tqdm import tqdm"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AgKjDChHXLe7",
        "colab_type": "text"
      },
      "source": [
        "## Prepare data\n",
        "In this step, we convert input and output files to numeric sequence with length 10 as the maximum length."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "PWulGtUEyueH",
        "colab": {}
      },
      "source": [
        "def preprocess_sentence(file_name):\n",
        "    '''\n",
        "    DESCRIPTION:\n",
        "    This function to read the file, then add <start> and <end> as a tag in begin and end for each sequence.\n",
        "    INPUT: \n",
        "    file_name: file name\n",
        "    OUTPUT: \n",
        "    text: text after preprocess\n",
        "    ''' \n",
        "    with open(file_name , 'r', encoding='windows-1256') as f:\n",
        "        text = f.readlines()\n",
        "\n",
        "    text = ['<start> '+ t.replace('\\n','') + ' <end>' for t in text]\n",
        "    return text\n",
        "\n",
        "\n",
        "def calculate_max_length(tensor):\n",
        "    '''\n",
        "    DESCRIPTION:\n",
        "    This function to Calculates the max length in tensor\n",
        "    INPUT: \n",
        "    tensor: input tensor\n",
        "    OUTPUT: \n",
        "    _: max length of tensor\n",
        "    ''' \n",
        "    return max(len(t) for t in tensor)\n",
        "\n",
        "def tokenize(text):\n",
        "    '''\n",
        "    DESCRIPTION:\n",
        "    This function to convert inputs to numeric sequences with the maximum length\n",
        "    INPUT: \n",
        "    text: list of string\n",
        "    OUTPUT: \n",
        "    tokenizer: object of converted text into a sequence of integer\n",
        "    text_vector: vector of converted text into a sequence of integer\n",
        "    max_length: max length in text_vector\n",
        "    ''' \n",
        "\n",
        "    # Choose the top 9000 words from the vocabulary\n",
        "    top_k = 9000\n",
        "    tokenizer = tf.keras.preprocessing.text.Tokenizer(num_words=top_k, oov_token=\"<unk>\",filters='')\n",
        "    tokenizer.fit_on_texts(text)\n",
        "    train_seqs = tokenizer.texts_to_sequences(text)\n",
        "\n",
        "    #add a word for padding \n",
        "    tokenizer.word_index['<pad>'] = 0\n",
        "    tokenizer.index_word[0] = '<pad>'\n",
        "\n",
        "    # Create the tokenized vectors\n",
        "    text_seqs = tokenizer.texts_to_sequences(text)\n",
        "\n",
        "    # Pad each vector to the max_length of the vector\n",
        "    text_vector = tf.keras.preprocessing.sequence.pad_sequences(text_seqs, padding='post')\n",
        "\n",
        "    # Calculates the max_length, which is used to store the attention weights\n",
        "    max_length = calculate_max_length(text_seqs)\n",
        "    \n",
        "    return tokenizer, text_vector,max_length"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "EJVB3qG1yueL",
        "colab": {}
      },
      "source": [
        "# prepare input data\n",
        "input = preprocess_sentence('input_pun.txt')\n",
        "input_tokenizer, input_tensor ,input_max_length = tokenize(input)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "XfOxkC0dyueO",
        "colab": {}
      },
      "source": [
        "# prepare output data\n",
        "target = preprocess_sentence('output_pun.txt')\n",
        "target_tokenizer, target_tensor ,target_max_length = tokenize(target)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ykixCCr20Hjg",
        "colab_type": "code",
        "outputId": "c75ce2f2-bcde-4375-954d-b9a31920547a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# data shapes\n",
        "(input_tensor.shape),(target_tensor.shape) "
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((26000, 12), (26000, 12))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "a38_ZKX6yueR",
        "outputId": "adbb5df4-11bc-4509-999d-eab8a06b9804",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 454
        }
      },
      "source": [
        "def convert(tokenizer, tensor):\n",
        "    '''\n",
        "    DESCRIPTION:\n",
        "    This function to convert index to word for input tensor\n",
        "    INPUT: \n",
        "    tokenizer: object of converted text into a sequence of integer\n",
        "    tensor: list of integer\n",
        "    OUTPUT: \n",
        "    None\n",
        "    ''' \n",
        "    for t in tensor:\n",
        "        if t!=0:\n",
        "              print (\"%d ----> %s\" % (t, tokenizer.index_word[t]))\n",
        "    \n",
        "print (\"Input Language; index to word mapping\")\n",
        "convert(input_tokenizer, input_tensor[0])  \n",
        "print (\"Output Language; index to word mapping\")\n",
        "convert(target_tokenizer, target_tensor[0]) "
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input Language; index to word mapping\n",
            "2 ----> <start>\n",
            "2760 ----> تم\n",
            "7016 ----> إعداد\n",
            "39 ----> هذا\n",
            "1 ----> <unk>\n",
            "1 ----> <unk>\n",
            "3667 ----> بواسطة\n",
            "1 ----> <unk>\n",
            "7017 ----> الشاملة\n",
            "1956 ----> الكتاب\n",
            "48 ----> شرح\n",
            "3 ----> <end>\n",
            "Output Language; index to word mapping\n",
            "3 ----> <start>\n",
            "2 ----> space\n",
            "2 ----> space\n",
            "2 ----> space\n",
            "2 ----> space\n",
            "2 ----> space\n",
            "2 ----> space\n",
            "2 ----> space\n",
            "2 ----> space\n",
            "5 ----> :\n",
            "2 ----> space\n",
            "4 ----> <end>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kZG-cQ4genhn",
        "colab_type": "text"
      },
      "source": [
        "### Data Visualization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PkEKybqyNghP",
        "colab_type": "code",
        "outputId": "2c9072c7-ccc3-4e8e-a409-e0fde807184a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 284
        }
      },
      "source": [
        "target_plot = pd.DataFrame(list(target_tokenizer.word_counts.items())) \n",
        "target_plot"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>&lt;start&gt;</td>\n",
              "      <td>26000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>space</td>\n",
              "      <td>218354</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>:</td>\n",
              "      <td>12962</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>&lt;end&gt;</td>\n",
              "      <td>26000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>.</td>\n",
              "      <td>12259</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>؛</td>\n",
              "      <td>3601</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>،</td>\n",
              "      <td>12614</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>؟</td>\n",
              "      <td>210</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         0       1\n",
              "0  <start>   26000\n",
              "1    space  218354\n",
              "2        :   12962\n",
              "3    <end>   26000\n",
              "4        .   12259\n",
              "5        ؛    3601\n",
              "6        ،   12614\n",
              "7        ؟     210"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gB1tRvqcKjvW",
        "colab_type": "code",
        "outputId": "dcb337dc-c833-4421-98eb-ad4566ee5d92",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        }
      },
      "source": [
        "plt.xticks(fontsize =10)\n",
        "plt.bar(target_plot[0],target_plot[1], color=(0.2, 0.4, 0.6, 0.6))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<BarContainer object of 8 artists>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYkAAAD4CAYAAAAZ1BptAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "goYcNYDMe6Fq",
        "colab_type": "text"
      },
      "source": [
        "### Create dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Uv9ycnIeyueW",
        "colab": {}
      },
      "source": [
        "BUFFER_SIZE = len(input_tensor)\n",
        "BATCH_SIZE = 256\n",
        "steps_per_epoch = len(input_tensor)//BATCH_SIZE\n",
        "embedding_dim = 128\n",
        "units = 1024\n",
        "vocab_inp_size = len(input_tokenizer.word_index)+1\n",
        "vocab_tar_size = len(target_tokenizer.word_index)+1\n",
        "\n",
        "# create dataset\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices((input_tensor, target_tensor)).shuffle(BUFFER_SIZE)\n",
        "train_dataset = train_dataset.batch(BATCH_SIZE, drop_remainder=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "K1slax4qyueZ",
        "outputId": "af3e1837-c679-440a-a312-5475f2abfe5f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "example_input_batch, example_target_batch = next(iter(train_dataset))\n",
        "example_input_batch.shape, example_target_batch.shape"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(TensorShape([Dimension(256), Dimension(12)]),\n",
              " TensorShape([Dimension(256), Dimension(12)]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NKzsyzvefDo2",
        "colab_type": "text"
      },
      "source": [
        "## Encoder and decoder model\n",
        "\n",
        "In this part of the code, we used the same technique of Neural Machine Translation provided by TensorFlow. However, we used Keras with the backend of TensorFlow. For more details can visit [Neural machine translation with attention tutorial](https://www.tensorflow.org/tutorials/text/nmt_with_attention)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "kEN7CY6lyued",
        "colab": {}
      },
      "source": [
        "class Encoder(tf.keras.Model):\n",
        "    def __init__(self, vocab_size, embedding_dim, enc_units, batch_sz):\n",
        "        super(Encoder, self).__init__()\n",
        "        self.batch_sz = batch_sz\n",
        "        self.enc_units = enc_units\n",
        "        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
        "        self.gru = tf.keras.layers.GRU(self.enc_units,\n",
        "                                       return_sequences=True,\n",
        "                                       return_state=True,\n",
        "                                       recurrent_initializer='glorot_uniform')\n",
        "\n",
        "    def call(self, x, hidden):\n",
        "        x = self.embedding(x)\n",
        "        output, state = self.gru(x, initial_state = hidden)\n",
        "        return output, state\n",
        "\n",
        "    def initialize_hidden_state(self):\n",
        "        return tf.zeros((self.batch_sz, self.enc_units))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dnVQwRhZ8vXZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class BahdanauAttention(tf.keras.layers.Layer):\n",
        "    def __init__(self, units):\n",
        "        super(BahdanauAttention, self).__init__()\n",
        "        self.W1 = tf.keras.layers.Dense(units)\n",
        "        self.W2 = tf.keras.layers.Dense(units)\n",
        "        self.V = tf.keras.layers.Dense(1)\n",
        "\n",
        "    def call(self, query, values):\n",
        "        # hidden shape == (batch_size, hidden size)\n",
        "        # hidden_with_time_axis shape == (batch_size, 1, hidden size)\n",
        "        # we are doing this to perform addition to calculate the score\n",
        "        hidden_with_time_axis = tf.expand_dims(query, 1)\n",
        "\n",
        "        # score shape == (batch_size, max_length, 1)\n",
        "        # we get 1 at the last axis because we are applying score to self.V\n",
        "        # the shape of the tensor before applying self.V is (batch_size, max_length, units)\n",
        "        score = self.V(tf.keras.layers.Activation(activation = \"tanh\")(tf.keras.layers.Add()([self.W1(values), self.W2(hidden_with_time_axis)])))    \n",
        "\n",
        "        # attention_weights shape == (batch_size, max_length, 1)\n",
        "        attention_weights = tf.keras.layers.Activation(activation = \"softmax\")(tf.keras.layers.Permute((2, 1))(score))\n",
        "        attention_weights = tf.keras.layers.Permute((2, 1))(attention_weights)\n",
        "\n",
        "        # context_vector shape after sum == (batch_size, hidden_size)\n",
        "        context_vector = tf.keras.layers.Multiply()([attention_weights, values])\n",
        "\n",
        "        context_vector = tf.reduce_sum(context_vector, axis=1)\n",
        "\n",
        "        return context_vector, attention_weights"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vzsSNvSa8vf9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Decoder(tf.keras.Model):\n",
        "    def __init__(self, vocab_size, embedding_dim, dec_units, batch_sz):\n",
        "        super(Decoder, self).__init__()\n",
        "        self.batch_sz = batch_sz\n",
        "        self.dec_units = dec_units\n",
        "        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
        "        self.gru = tf.keras.layers.GRU(self.dec_units,\n",
        "                                       return_sequences=True,\n",
        "                                       return_state=True,\n",
        "                                       recurrent_initializer='glorot_uniform')\n",
        "        self.fc = tf.keras.layers.Dense(vocab_size)\n",
        "\n",
        "        # used for attention\n",
        "        self.attention = BahdanauAttention(self.dec_units)\n",
        "\n",
        "    def call(self, x, hidden, enc_output):\n",
        "        # enc_output shape == (batch_size, max_length, hidden_size)\n",
        "        context_vector, attention_weights = self.attention(hidden, enc_output)\n",
        "\n",
        "        # x shape after passing through embedding == (batch_size, 1, embedding_dim)\n",
        "        x = self.embedding(x)\n",
        "\n",
        "        # x shape after concatenation == (batch_size, 1, embedding_dim + hidden_size)\n",
        "        x = tf.keras.layers.Concatenate(axis = -1)([tf.expand_dims(context_vector, 1), x])\n",
        "\n",
        "        # passing the concatenated vector to the GRU\n",
        "        output, state = self.gru(x)\n",
        "\n",
        "        #output = tf.keras.layers.Dense(self.dec_units)(output)\n",
        "        # output shape == (batch_size * 1, hidden_size)\n",
        "        output = tf.keras.layers.Reshape((output.shape[2],))(output)\n",
        "\n",
        "        # output shape == (batch_size, vocab)\n",
        "        x = self.fc(output)\n",
        "\n",
        "        return x, state, attention_weights"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ax5I6Vm8yuef",
        "colab": {}
      },
      "source": [
        "encoder = Encoder(vocab_inp_size, embedding_dim, units, BATCH_SIZE)\n",
        "\n",
        "# sample input\n",
        "sample_hidden = encoder.initialize_hidden_state()\n",
        "\n",
        "sample_output, sample_hidden = encoder(example_input_batch, sample_hidden)\n",
        "\n",
        "\n",
        "attention_layer = BahdanauAttention(10)\n",
        "attention_result, attention_weights = attention_layer(sample_hidden, sample_output)\n",
        "\n",
        "decoder = Decoder(vocab_tar_size, embedding_dim, units, BATCH_SIZE)\n",
        "\n",
        "sample_decoder_output, _, _ = decoder(tf.random.uniform((BATCH_SIZE, 1)),\n",
        "                                      sample_hidden, sample_output)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X7w7QsJ-nkg7",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "### Optimizer and loss function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "4ib4lh5Hyueu",
        "colab": {}
      },
      "source": [
        "optimizer = tf.keras.optimizers.Adam()\n",
        "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(\n",
        "    from_logits=True, reduction='none')\n",
        "\n",
        "def loss_function(real, pred):\n",
        "    mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
        "    loss_ = loss_object(real, pred)\n",
        "\n",
        "    mask = tf.cast(mask, dtype=loss_.dtype)\n",
        "    loss_ *= mask\n",
        "\n",
        "    return tf.reduce_mean(loss_)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "8pl0Bj4hyuew",
        "colab": {}
      },
      "source": [
        "checkpoint_dir = './training_checkpoints5'\n",
        "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
        "checkpoint = tf.train.Checkpoint(optimizer=optimizer,\n",
        "                                 encoder=encoder,\n",
        "                                 decoder=decoder)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Df6rittahBG-",
        "colab_type": "text"
      },
      "source": [
        "### Train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "J8XDHnUQyue0",
        "colab": {}
      },
      "source": [
        "\n",
        "@tf.function\n",
        "def train_step(inp, targ, enc_hidden):\n",
        "    '''\n",
        "    DESCRIPTION:\n",
        "    This function to train encode-decode model\n",
        "    INPUT: \n",
        "    inp: input vector\n",
        "    targ: target vector\n",
        "    enc_hidden: encoder initial hidden state\n",
        "    OUTPUT: \n",
        "    batch_loss: train loss\n",
        "    ''' \n",
        "\n",
        "    loss = 0\n",
        "    accuracy=0\n",
        "    with tf.GradientTape() as tape:\n",
        "        enc_output, enc_hidden = encoder(inp, enc_hidden)\n",
        "\n",
        "        dec_hidden = enc_hidden\n",
        "\n",
        "        dec_input = tf.expand_dims([target_tokenizer.word_index['<start>']] * BATCH_SIZE, 1)\n",
        "\n",
        "        # Teacher forcing - feeding the target as the next input\n",
        "        for t in range(1, targ.shape[1]):\n",
        "          # passing enc_output to the decoder\n",
        "          predictions, dec_hidden, _ = decoder(dec_input, dec_hidden, enc_output)\n",
        "\n",
        "          loss += loss_function(targ[:, t], predictions)\n",
        "\n",
        "          # using teacher forcing\n",
        "          dec_input = tf.expand_dims(targ[:, t], 1)\n",
        "\n",
        "    batch_loss = (loss / int(targ.shape[1]))\n",
        "\n",
        "    variables = encoder.trainable_variables + decoder.trainable_variables\n",
        "\n",
        "    gradients = tape.gradient(loss, variables)\n",
        "\n",
        "    optimizer.apply_gradients(zip(gradients, variables))\n",
        "\n",
        "    return batch_loss\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3wA2-LY_A-xt",
        "colab_type": "code",
        "outputId": "b8314b7d-1bbc-4cb6-bbd1-4346a6293882",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 927
        }
      },
      "source": [
        "EPOCHS = 10\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "  start = time.time()\n",
        "\n",
        "  enc_hidden = encoder.initialize_hidden_state()\n",
        "  total_loss = 0\n",
        "\n",
        "  for (batch, (inp, targ)) in enumerate(train_dataset.take(steps_per_epoch)):\n",
        "    batch_loss = train_step(inp, targ, enc_hidden)\n",
        "    total_loss += batch_loss\n",
        "\n",
        "    if batch % 100 == 0:\n",
        "      print('Epoch {} Batch {} Loss {:.4f}'.format(epoch + 1,\n",
        "                                                   batch,\n",
        "                                                   batch_loss.numpy()))\n",
        "  # saving (checkpoint) the model every 2 epochs\n",
        "  if (epoch + 1) % 2 == 0:\n",
        "    checkpoint.save(file_prefix = checkpoint_prefix)\n",
        "\n",
        "  print('Epoch {} Loss {:.4f}'.format(epoch + 1,\n",
        "                                      total_loss / steps_per_epoch))\n",
        "  print('Time taken for 1 epoch {} sec\\n'.format(time.time() - start))"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "Epoch 1 Batch 0 Loss 2.1982\n",
            "Epoch 1 Batch 100 Loss 0.8168\n",
            "Epoch 1 Loss 0.9368\n",
            "Time taken for 1 epoch 52.682173013687134 sec\n",
            "\n",
            "Epoch 2 Batch 0 Loss 0.8119\n",
            "Epoch 2 Batch 100 Loss 0.7599\n",
            "Epoch 2 Loss 0.7738\n",
            "Time taken for 1 epoch 24.720882177352905 sec\n",
            "\n",
            "Epoch 3 Batch 0 Loss 0.7666\n",
            "Epoch 3 Batch 100 Loss 0.6111\n",
            "Epoch 3 Loss 0.6817\n",
            "Time taken for 1 epoch 24.27721619606018 sec\n",
            "\n",
            "Epoch 4 Batch 0 Loss 0.5943\n",
            "Epoch 4 Batch 100 Loss 0.3905\n",
            "Epoch 4 Loss 0.4679\n",
            "Time taken for 1 epoch 24.67871403694153 sec\n",
            "\n",
            "Epoch 5 Batch 0 Loss 0.5627\n",
            "Epoch 5 Batch 100 Loss 0.3177\n",
            "Epoch 5 Loss 0.3922\n",
            "Time taken for 1 epoch 24.29068875312805 sec\n",
            "\n",
            "Epoch 6 Batch 0 Loss 0.3334\n",
            "Epoch 6 Batch 100 Loss 0.2579\n",
            "Epoch 6 Loss 0.3061\n",
            "Time taken for 1 epoch 24.555397510528564 sec\n",
            "\n",
            "Epoch 7 Batch 0 Loss 0.2775\n",
            "Epoch 7 Batch 100 Loss 0.2657\n",
            "Epoch 7 Loss 0.4454\n",
            "Time taken for 1 epoch 24.277432441711426 sec\n",
            "\n",
            "Epoch 8 Batch 0 Loss 0.2752\n",
            "Epoch 8 Batch 100 Loss 0.2295\n",
            "Epoch 8 Loss 0.3803\n",
            "Time taken for 1 epoch 24.637281894683838 sec\n",
            "\n",
            "Epoch 9 Batch 0 Loss 0.2407\n",
            "Epoch 9 Batch 100 Loss 0.2174\n",
            "Epoch 9 Loss 0.3256\n",
            "Time taken for 1 epoch 24.301697731018066 sec\n",
            "\n",
            "Epoch 10 Batch 0 Loss 0.2219\n",
            "Epoch 10 Batch 100 Loss 0.1915\n",
            "Epoch 10 Loss 0.2341\n",
            "Time taken for 1 epoch 24.560333013534546 sec\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "urD0m-005ooX",
        "colab_type": "code",
        "outputId": "774d73ec-7e56-4db3-a255-15018a161285",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# restoring the latest checkpoint in checkpoint_dir\n",
        "checkpoint.restore(tf.train.latest_checkpoint(checkpoint_dir))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7f33ea6e2d30>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pgfHSUhgiETN",
        "colab_type": "text"
      },
      "source": [
        "### Predict"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "qIT8TVVpyue7",
        "colab": {}
      },
      "source": [
        "def evaluate(sentence):\n",
        "    '''\n",
        "    DESCRIPTION:\n",
        "    This function to predict result\n",
        "    INPUT: \n",
        "    sentence: input sentence \n",
        "    OUTPUT: \n",
        "    result: predict result\n",
        "    sentence: input sentence \n",
        "    attention_plot: attention weights\n",
        "    ''' \n",
        "    attention_plot = np.zeros((target_max_length, input_max_length))\n",
        "\n",
        "    #sentence = preprocess_sentence(sentence)\n",
        "    sentence = '<start> '+sentence + ' <end>'\n",
        "    \n",
        "    inputs = [input_tokenizer.texts_to_sequences([i])[0][0] for i in sentence.split(' ')]\n",
        "    inputs = tf.keras.preprocessing.sequence.pad_sequences([inputs],\n",
        "                                                         maxlen=input_max_length,\n",
        "                                                         padding='post')\n",
        "    inputs = tf.convert_to_tensor(inputs)\n",
        "    \n",
        "    result = ''\n",
        "\n",
        "    hidden = [tf.zeros((1, units))]\n",
        "    enc_out, enc_hidden = encoder(inputs, hidden)\n",
        "    dec_hidden = enc_hidden\n",
        "    dec_input = tf.expand_dims([target_tokenizer.word_index['<start>']], 0)\n",
        "\n",
        "    for t in range(target_max_length):\n",
        "        predictions, dec_hidden, attention_weights = decoder(dec_input,\n",
        "                                                         dec_hidden,\n",
        "                                                         enc_out)\n",
        "\n",
        "        # storing the attention weights to plot later on\n",
        "        attention_weights = tf.reshape(attention_weights, (-1, ))\n",
        "        attention_plot[t] = attention_weights.numpy()\n",
        "\n",
        "        predicted_id = tf.argmax(predictions[0]).numpy()\n",
        "\n",
        "        result += target_tokenizer.index_word[predicted_id] + ' '\n",
        "\n",
        "        if target_tokenizer.index_word[predicted_id] == '<end>':\n",
        "            return result, sentence, attention_plot\n",
        "\n",
        "        # the predicted ID is fed back into the model\n",
        "        dec_input = tf.expand_dims([predicted_id], 0)\n",
        "\n",
        "    return result, sentence, attention_plot"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "C7J0Y5qoyue9",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "wSpX2iMB3Gfl",
        "colab": {}
      },
      "source": [
        "# function for plotting the attention weights\n",
        "def plot_attention(attention, sentence, predicted_sentence):\n",
        "  '''\n",
        "    DESCRIPTION:\n",
        "    This function to plot attention \n",
        "    INPUT: \n",
        "    attention: attention weights\n",
        "    sentence: input sentence \n",
        "    predicted_sentence: predict result\n",
        "\n",
        "    OUTPUT: \n",
        "    None\n",
        "    ''' \n",
        "  fig = plt.figure(figsize=(10,10))\n",
        "  ax = fig.add_subplot(1, 1, 1)\n",
        "  ax.matshow(attention, cmap='viridis')\n",
        "\n",
        "  fontdict = {'fontsize': 14}\n",
        "\n",
        "  ax.set_xticklabels([''] + sentence, fontdict=fontdict, rotation=90)\n",
        "  ax.set_yticklabels([''] + predicted_sentence, fontdict=fontdict)\n",
        "\n",
        "  ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
        "  ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
        "\n",
        "  plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "EX-v514W3GlB",
        "colab": {}
      },
      "source": [
        "def predict(sentence):\n",
        "    '''\n",
        "    DESCRIPTION:\n",
        "    This function to predict output sentence\n",
        "\n",
        "    INPUT: \n",
        "    sentence: input sentence \n",
        "\n",
        "    OUTPUT: \n",
        "    None\n",
        "    ''' \n",
        "    result, sentence, attention_plot = evaluate(sentence)\n",
        "\n",
        "    print('Input:\\n %s' % (sentence))\n",
        "\n",
        "    predict = ''\n",
        "    sentence_list = sentence.split(' ')\n",
        "    sentence_list.pop(0) # remove <start>\n",
        "    result_list = result.split(' ')\n",
        "\n",
        "    for i in range(len(sentence_list)):\n",
        "      if (result_list[i]=='space'):\n",
        "        predict += sentence_list[i]+' '\n",
        "      else:\n",
        "        predict += sentence_list[i]+result_list[i]+' '\n",
        "    print('Predicted punctuation:\\n {}'.format(predict))\n",
        "\n",
        "    attention_plot = attention_plot[:len(result.split(' ')), :len(sentence.split(' '))]\n",
        "    plot_attention(attention_plot, sentence_list, result_list)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SJRpYQCq9Q7K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "fFj-3K0Ryue_",
        "outputId": "66478110-38e5-40a5-de35-932a447e944d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 740
        }
      },
      "source": [
        "real_sentence = 'قال محمد : السلام عليكم'\n",
        "#real_sentence = 'نجح محمد في الامتحان ؛ لأنه اجتهد في دروسه.'\n",
        "sentence = 'قال محمد السلام عليكم'\n",
        "print('Original Text: ',real_sentence)\n",
        "\n",
        "in_seq = sentence.strip().split(' ')\n",
        "n =10\n",
        "in_sequances = [\" \".join(in_seq[i:i+n]) for i in range(0, len(in_seq), n)]\n",
        "[predict(s) for s in in_sequances]"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Original Text:  قال محمد : السلام عليكم\n",
            "Input:\n",
            " <start> قال محمد السلام عليكم <end>\n",
            "Predicted punctuation:\n",
            " قال محمد: السلام عليكم <end> \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAU4AAAJuCAYAAADfF+vCAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n/w8zRiEAal99KgAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 720x720 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[None]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WBGn_Pur9UHI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "def evaluate_model( sentences, target):\n",
        "  '''\n",
        "  DESCRIPTION:\n",
        "  This function to evaluate model \n",
        "  INPUT: \n",
        "  sentences: input vector\n",
        "  target: target vector\n",
        "  OUTPUT: \n",
        "  actual: real target sentences\n",
        "  predicted: predict target sentences\n",
        "  ''' \n",
        "  actual, predicted = list(), list()\n",
        "  outer = tqdm(range(len(sentences)),leave=True,position =0)\n",
        "  for i, sentence in enumerate(sentences):\n",
        "    # translate encoded source text\n",
        "    #sentence = sentence.reshape((1, sentence.shape[0]))\n",
        "    predict,raw_src,_ = evaluate(sentence)\n",
        "    predict = predict.replace(' <end> ','')\n",
        "    raw_target = target[i]\n",
        "    if i < 10:\n",
        "      print('src=[%s], target=[%s], predicted=[%s]' % (sentence, raw_target, predict))\n",
        "    actual.append([raw_target.split()])\n",
        "    predicted.append(predict.split())\n",
        "    outer.update(1)\n",
        "\n",
        "  return actual, predicted\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SLAE4hcm9X_3",
        "colab_type": "code",
        "outputId": "8ead87ee-366e-4e69-88c2-4682e4cb2a6b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 222
        }
      },
      "source": [
        "input_ = np.array(input)\n",
        "input_ = [ t.replace(' <end>','') for t in input_]\n",
        "input_ = [ t.replace('<start> ','') for t in input_]\n",
        "\n",
        "target_ = np.array(target)\n",
        "target_ = [ t.replace(' <end>','') for t in target_]\n",
        "target_ = [ t.replace('<start> ','') for t in target_]\n",
        "\n",
        "actual, predicted = evaluate_model(input_,target_)\n"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  0%|          | 1/26000 [00:00<1:42:50,  4.21it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "src=[تم إعداد هذا الملف آليا بواسطة المكتبة الشاملة الكتاب شرح], target=[space space space space space space space space : space], predicted=[space space space space space space space space : space]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r  0%|          | 2/26000 [00:00<1:43:01,  4.21it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "src=[البهجة الوردية مصدر الكتاب موقع الإسلام [ الكتاب مشكول ومرقم], target=[space space space : space space space space space space], predicted=[space space space : space space space space space space]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r  0%|          | 3/26000 [00:00<1:43:15,  4.20it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "src=[على سيدنا محمد وعلى آله وصحبه وسلم تسليما كثيرا رب], target=[space space space space space space space space . space], predicted=[space space space space space space space space . space]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r  0%|          | 4/26000 [00:00<1:45:29,  4.11it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "src=[يسر واعف واختم بخير قال الشيخ الإمام العالم العلامة الرحالة], target=[space space space . space space space space space space], predicted=[space space space space space space space space space space]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r  0%|          | 5/26000 [00:01<1:45:14,  4.12it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "src=[بسم الله الرحمن الرحيم أي أبتدئ أو أؤلف إذ كل], target=[space space space space : space space space space space], predicted=[space space space space : space space space space space]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r  0%|          | 6/26000 [00:01<1:44:31,  4.14it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "src=[فاعل يبدأ في فعله ببسم الله يضمر ما جعل التسمية], target=[space space space space space . space space space space], predicted=[space space space space space space space space space space]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r  0%|          | 7/26000 [00:01<1:45:03,  4.12it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "src=[مبدأ له كما أن المسافر إذا حل أو ارتحل فقال], target=[space space space space space space space space space :], predicted=[space space space space space space space space space :]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r  0%|          | 8/26000 [00:01<1:45:27,  4.11it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "src=[والاسم مشتق من السمو وهو العلو وقيل من الوسم وهو], target=[space space space space space space : space space space], predicted=[space space space space space space : space space space]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r  0%|          | 9/26000 [00:02<1:48:41,  3.99it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "src=[العلامة لأن كل ما سمي فقد نوه باسمه ووسم والله], target=[؛ space space space space space space space . space], predicted=[؛ space space space space space space space space space]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r  0%|          | 10/26000 [00:02<1:46:48,  4.06it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "src=[علم للذات الواجب الوجود وأصله الإله حذفت همزته وعوض منها], target=[space space space ، space space space space space space], predicted=[space space space ، space space space space space space]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 26000/26000 [1:42:25<00:00,  4.11it/s]"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LJPjM1aoXx6G",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b59ee545-ea61-483d-b7f3-7b7051903bfc"
      },
      "source": [
        "\n",
        "# calculate BLEU score\n",
        "print('BLEU: %f' % corpus_bleu(actual, predicted))"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "BLEU: 0.867986\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2uOC3rx8SiKu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}